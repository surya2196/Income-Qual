{"nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {}, "source": ["\n<h2 id=\"INCOME-QUALIFICATION\">INCOME QUALIFICATION<a class=\"anchor-link\" href=\"#INCOME-QUALIFICATION\">\u00b6</a></h2>\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n<h3 id=\"Import-the-required-libraries\">Import the required libraries<a class=\"anchor-link\" href=\"#Import-the-required-libraries\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nimport os\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nimport warnings\nwarnings.filterwarnings('ignore')\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Load-the-train-and-test-data\">Load the train and test data<a class=\"anchor-link\" href=\"#Load-the-train-and-test-data\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ntrain=pd.read_csv('~/train.csv')\ntest=pd.read_csv('~/test.csv')\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nprint('Shape of train dataset is {}'.format(train.shape))\nprint('Shape of test dataset is {}'.format(test.shape))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain.head()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Let-us-identify-our-target-variable\">Let us identify our target variable<a class=\"anchor-link\" href=\"#Let-us-identify-our-target-variable\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ntest.head()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nfor i in train.columns:\n    if i not in test.columns:\n        print(\"Our Target variable is {}\".format(i))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Lets-understand-the-type-of-data\">Lets understand the type of data<a class=\"anchor-link\" href=\"#Lets-understand-the-type-of-data\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nprint(train.dtypes.value_counts())\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nprint(train.info())\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n#lets explore each different types of datasets\nfor i in train.columns:\n    a = train[i].dtype\n    if a == 'object':\n        print(i)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n# lets drop Id variable.\n\ntrain.drop(['Id','idhogar'],axis=1,inplace=True)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain['dependency'].value_counts()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ndef map(i):\n    \n    if i=='yes':\n        return(float(1))\n    elif i=='no':\n        return(float(0))\n    else:\n        return(float(i))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain['dependency']=train['dependency'].apply(map)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nfor i in train.columns:\n    a=train[i].dtype\n    if a == 'object':\n        print(i)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain.info()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain['edjefe']=train['edjefe'].apply(map)\ntrain['edjefa']=train['edjefa'].apply(map)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain.info()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nvar_df=pd.DataFrame(np.var(train,0),columns=['variance'])\nvar_df.sort_values(by='variance').head(15)\nprint('Below are columns with variance 0.')\ncol=list((var_df[var_df['variance']==0]).index)\nprint(col)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Check-if-there-are-any-biases-in-the-dataset\">Check if there are any biases in the dataset<a class=\"anchor-link\" href=\"#Check-if-there-are-any-biases-in-the-dataset\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ncontingency_tab=pd.crosstab(train['r4t3'],train['hogar_total'])\nObserved_Values=contingency_tab.values\nimport scipy.stats\nb=scipy.stats.chi2_contingency(contingency_tab)\nExpected_Values = b[3]\nno_of_rows=len(contingency_tab.iloc[0:2,0])\nno_of_columns=len(contingency_tab.iloc[0,0:2])\ndf=(no_of_rows-1)*(no_of_columns-1)\nprint(\"Degree of Freedom:-\",df)\nfrom scipy.stats import chi2\nchi_square=sum([(o-e)**2./e for o,e in zip(Observed_Values,Expected_Values)])\nchi_square_statistic=chi_square[0]+chi_square[1]\nprint(\"chi-square statistic:-\",chi_square_statistic)\nalpha=0.05\ncritical_value=chi2.ppf(q=1-alpha,df=df)\nprint('critical_value:',critical_value)\np_value=1-chi2.cdf(x=chi_square_statistic,df=df)\nprint('p-value:',p_value)\nprint('Significance level: ',alpha)\nprint('Degree of Freedom: ',df)\nprint('chi-square statistic:',chi_square_statistic)\nprint('critical_value:',critical_value)\nprint('p-value:',p_value)\nif chi_square_statistic>=critical_value:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n    \nif p_value<=alpha:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ncontingency_tab=pd.crosstab(train['tipovivi3'],train['v2a1'])\nObserved_Values=contingency_tab.values\nimport scipy.stats\nb=scipy.stats.chi2_contingency(contingency_tab)\nExpected_Values = b[3]\nno_of_rows=len(contingency_tab.iloc[0:2,0])\nno_of_columns=len(contingency_tab.iloc[0,0:2])\ndf=(no_of_rows-1)*(no_of_columns-1)\nprint(\"Degree of Freedom:-\",df)\nfrom scipy.stats import chi2\nchi_square=sum([(o-e)**2./e for o,e in zip(Observed_Values,Expected_Values)])\nchi_square_statistic=chi_square[0]+chi_square[1]\nprint(\"chi-square statistic:-\",chi_square_statistic)\nalpha=0.05\ncritical_value=chi2.ppf(q=1-alpha,df=df)\nprint('critical_value:',critical_value)\np_value=1-chi2.cdf(x=chi_square_statistic,df=df)\nprint('p-value:',p_value)\nprint('Significance level: ',alpha)\nprint('Degree of Freedom: ',df)\nprint('chi-square statistic:',chi_square_statistic)\nprint('critical_value:',critical_value)\nprint('p-value:',p_value)\nif chi_square_statistic>=critical_value:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n    \nif p_value<=alpha:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nObserved_Values=contingency_tab.values\nimport scipy.stats\nb=scipy.stats.chi2_contingency(contingency_tab)\nExpected_Values = b[3]\nno_of_rows=len(contingency_tab.iloc[0:2,0])\nno_of_columns=len(contingency_tab.iloc[0,0:2])\ndf=(no_of_rows-1)*(no_of_columns-1)\nprint(\"Degree of Freedom:-\",df)\nfrom scipy.stats import chi2\nchi_square=sum([(o-e)**2./e for o,e in zip(Observed_Values,Expected_Values)])\nchi_square_statistic=chi_square[0]+chi_square[1]\nprint(\"chi-square statistic:-\",chi_square_statistic)\nalpha=0.05\ncritical_value=chi2.ppf(q=1-alpha,df=df)\nprint('critical_value:',critical_value)\np_value=1-chi2.cdf(x=chi_square_statistic,df=df)\nprint('p-value:',p_value)\nprint('Significance level: ',alpha)\nprint('Degree of Freedom: ',df)\nprint('chi-square statistic:',chi_square_statistic)\nprint('critical_value:',critical_value)\nprint('p-value:',p_value)\nif chi_square_statistic>=critical_value:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n    \nif p_value<=alpha:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ncontingency_tab=pd.crosstab(train['v18q'],train['v18q1'])\nObserved_Values=contingency_tab.values\nimport scipy.stats\nb=scipy.stats.chi2_contingency(contingency_tab)\nExpected_Values = b[3]\nno_of_rows=len(contingency_tab.iloc[0:2,0])\nno_of_columns=len(contingency_tab.iloc[0,0:2])\ndf=(no_of_rows-1)*(no_of_columns-1)\nprint(\"Degree of Freedom:-\",df)\nfrom scipy.stats import chi2\nchi_square=sum([(o-e)**2./e for o,e in zip(Observed_Values,Expected_Values)])\nchi_square_statistic=chi_square[0]+chi_square[1]\nprint(\"chi-square statistic:-\",chi_square_statistic)\nalpha=0.05\ncritical_value=chi2.ppf(q=1-alpha,df=df)\nprint('critical_value:',critical_value)\np_value=1-chi2.cdf(x=chi_square_statistic,df=df)\nprint('p-value:',p_value)\nprint('Significance level: ',alpha)\nprint('Degree of Freedom: ',df)\nprint('chi-square statistic:',chi_square_statistic)\nprint('critical_value:',critical_value)\nprint('p-value:',p_value)\nif chi_square_statistic>=critical_value:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n    \nif p_value<=alpha:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Conclusion-:-Therefore,variables-('v18q','v18q1')-have-relationship-between-them.\">Conclusion : Therefore,variables ('v18q','v18q1') have relationship between them.<a class=\"anchor-link\" href=\"#Conclusion-:-Therefore,variables-('v18q','v18q1')-have-relationship-between-them.\">\u00b6</a></h3><h3 id=\"Hence,-there-is-bias-in-our-dataset.\">Hence, there is bias in our dataset.<a class=\"anchor-link\" href=\"#Hence,-there-is-bias-in-our-dataset.\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ntrain.drop('r4t3',axis=1,inplace=True)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Check-if-there-is-a-house-without-a-family-head\">Check if there is a house without a family head<a class=\"anchor-link\" href=\"#Check-if-there-is-a-house-without-a-family-head\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ntrain.parentesco1.value_counts()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\npd.crosstab(train['edjefa'],train['edjefe'])\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<ul>\n<li>Interpretation : Above cross tab shows 0 male head and 0 female head which implies that there are 435 families with no family head.</li>\n</ul>\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n<h3 id=\"Count-how-many-null-values-are-existing-in-columns.\">Count how many null values are existing in columns.<a class=\"anchor-link\" href=\"#Count-how-many-null-values-are-existing-in-columns.\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ntrain.isna().sum().value_counts()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Remove-null-value-rows-of-the-target-variable.\">Remove null value rows of the target variable.<a class=\"anchor-link\" href=\"#Remove-null-value-rows-of-the-target-variable.\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ntrain['Target'].isna().sum()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<ul>\n<li>Interpretation : There are no null values in Target variable.</li>\n</ul>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nfloat_col=[]\nfor i in train.columns:\n    a=train[i].dtype\n    if a == 'float64':\n        float_col.append(i)\nprint(float_col)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain[float_col].isna().sum()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain['v18q1'].value_counts()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\npd.crosstab(train['tipovivi1'],train['v2a1'])\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\npd.crosstab(train['v18q1'],train['v18q'])\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<ul>\n<li>Interpretation and action : 'v2a1', 'v18q1', 'rez_esc' have more than 50% null values, because for v18q1, there are families with their own house so they won't pay rent in that case it should be 0 and similar is for v18q1 there can be families with 0 tablets.</li>\n</ul>\n<p>Istead we can drop a column tipovivi3,v18q</p>\n<p>tipovivi3, =1 rented\nv18q, owns a tablet\nas v2a1 alone can show both **as v18q1 alone can show that if respondent owns a tablet or not</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ntrain['v2a1'].fillna(0,inplace=True)\ntrain['v18q1'].fillna(0,inplace=True)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain.drop(['tipovivi3', 'v18q','rez_esc','elimbasu5'],axis=1,inplace=True)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain['meaneduc'].fillna(np.mean(train['meaneduc']),inplace=True)\ntrain['SQBmeaned'].fillna(np.mean(train['SQBmeaned']),inplace=True)\nprint(train.isna().sum().value_counts())\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nint_col=[]\nfor i in train.columns:\n    a=train[i].dtype\n    if a == 'int64':\n        int_col.append(i)\nprint(int_col)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntrain[int_col].isna().sum().value_counts()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<ul>\n<li>Interpretation : Now there is no null value in our dataset.</li>\n</ul>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\ntrain.Target.value_counts()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Set-poverty-level-of-the-members-and-the-head-of-the-house-within-a-family.\">Set poverty level of the members and the head of the house within a family.<a class=\"anchor-link\" href=\"#Set-poverty-level-of-the-members-and-the-head-of-the-house-within-a-family.\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nPoverty_level=train[train['v2a1'] !=0]\nPoverty_level.shape\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\npoverty_level=Poverty_level.groupby('area1')['v2a1'].apply(np.median)\npoverty_level\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ndef povert(x):\n    if x<8000:\n        return('Below poverty level')\n    \n    elif x>140000:\n        return('Above poverty level')\n    elif x<140000:\n        return('Below poverty level: Ur-ban ; Above poverty level : Rural ')\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nc=Poverty_level['v2a1'].apply(povert)\nc.shape\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\npd.crosstab(c,Poverty_level['area1'])\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<ul>\n<li>Interpretation :</li>\n</ul>\n<p>There are total 1242 people above poverty level independent of area whether rural or Urban\nRemaining 1111 people level depends on their area\nRural :</p>\n<p>Above poverty level= 445</p>\n<p>Urban :</p>\n<p>Above poverty level =1103</p>\n<p>Below poverty level=1081</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nX_data=train.drop('Target',axis=1)\nY_data=train.Target\nX_data_col=X_data.columns\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Standard-Scalling\">Standard Scalling<a class=\"anchor-link\" href=\"#Standard-Scalling\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nfrom sklearn.preprocessing import StandardScaler\nSS=StandardScaler()\nX_data_1=SS.fit_transform(X_data)\nX_data_1=pd.DataFrame(X_data_1,columns=X_data_col)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Now-we-will-fit-the-model\">Now we will fit the model<a class=\"anchor-link\" href=\"#Now-we-will-fit-the-model\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nX_train,X_test,Y_train,Y_test=train_test_split(X_data_1,Y_data,test_size=0.25,stratify=Y_data,random_state=0)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\nrfc=RandomForestClassifier(random_state=0)\nparameters={'n_estimators':[10,50,100,300],'max_depth':[3,5,10,15]}\ngrid=zip([rfc],[parameters])\n\nbest_=None\n\nfor i, j in grid:\n    a=GridSearchCV(i,param_grid=j,cv=3,n_jobs=1)\n    a.fit(X_train,Y_train)\n    if best_ is None:\n        best_=a\n    elif a.best_score_>best_.best_score_:\n        best_=a\nprint (\"Best CV Score\",best_.best_score_)\nprint (\"Model Parameters\",best_.best_params_)\nprint(\"Best Estimator\",best_.best_estimator_)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nRFC=best_.best_estimator_\nModel=RFC.fit(X_train,Y_train)\npred=Model.predict(X_test)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nprint('Model Score of train data : {}'.format(Model.score(X_train,Y_train)))\nprint('Model Score of test data : {}'.format(Model.score(X_test,Y_test)))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nImportant_features=pd.DataFrame(Model.feature_importances_,X_data_col,columns=['feature_importance'])\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nTop50Features=Important_features.sort_values(by='feature_importance',ascending=False).head(50).index\nTop50Features\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nfor i in Top50Features:\n    if i not in X_data_col:\n        print(i)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nX_data_Top50=X_data[Top50Features]\nX_train,X_test,Y_train,Y_test=train_test_split(X_data_Top50,Y_data,test_size=0.25,stratify=Y_data,random_state=0)\nModel_1=RFC.fit(X_train,Y_train)\npred=Model_1.predict(X_test)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nfrom sklearn.metrics import confusion_matrix,f1_score,accuracy_score\nconfusion_matrix(Y_test,pred)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nf1_score(Y_test,pred,average='weighted')\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\naccuracy_score(Y_test,pred)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Lets-clean-the-test-data-and-then-find-predictions-for-it\">Lets clean the test data and then find predictions for it<a class=\"anchor-link\" href=\"#Lets-clean-the-test-data-and-then-find-predictions-for-it\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# lets drop Id variable.\ntest.drop('r4t3',axis=1,inplace=True)\ntest.drop(['Id','idhogar'],axis=1,inplace=True)\ntest['dependency']=test['dependency'].apply(map)\ntest['edjefe']=test['edjefe'].apply(map)\ntest['edjefa']=test['edjefa'].apply(map)\ntest['v2a1'].fillna(0,inplace=True)\ntest['v18q1'].fillna(0,inplace=True)\ntest.drop(['tipovivi3', 'v18q','rez_esc','elimbasu5'],axis=1,inplace=True)\ntrain['meaneduc'].fillna(np.mean(train['meaneduc']),inplace=True)\ntrain['SQBmeaned'].fillna(np.mean(train['SQBmeaned']),inplace=True)\ntest_data=test[Top50Features]\ntest_data.isna().sum().value_counts()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntest_data.SQBmeaned.fillna(np.mean(test_data['SQBmeaned']),inplace=True)\ntest_data.meaneduc.fillna(np.mean(test_data['meaneduc']),inplace=True)\nTest_data_1=SS.fit_transform(test_data)\nX_data_1=pd.DataFrame(Test_data_1)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\ntest_prediction=Model_1.predict(test_data)\ntest_prediction\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h2 id=\"Conclusion-:-Using-Random-Forest-Classifier-we-can-predict-test_data-with-accuracy-of-90%.\">Conclusion : Using Random Forest Classifier we can predict test_data with accuracy of 90%.<a class=\"anchor-link\" href=\"#Conclusion-:-Using-Random-Forest-Classifier-we-can-predict-test_data-with-accuracy-of-90%.\">\u00b6</a></h2>\n"], "cell_type": "markdown"}], "metadata": {}}